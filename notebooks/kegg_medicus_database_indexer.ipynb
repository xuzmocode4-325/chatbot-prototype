{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv \n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key =  os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(temperature=0.0, model_name='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'cl100k_base'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken \n",
    "tiktoken.encoding_for_model('gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "def tiktoken_len(text):\n",
    "    tokens = tokenizer.encode(\n",
    "        text,\n",
    "        disallowed_special=()\n",
    "    )\n",
    "    return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    "    openai_api_key=os.environ['OPENAI_API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_examples = [\"I am a text example\", \n",
    "                 \"I am another text example\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = embed.embed_documents(text_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Raw Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_medicus_drug = 'raw_datasets/kegg_medicus_drug_en.csv'\n",
    "kegg_medicus_disease = 'raw_datasets/kegg_medicus_disease_en.csv'\n",
    "kegg_medicus_dgroup = 'raw_datasets/kegg_medicus_dgroup_en.csv'\n",
    "kegg_medicus_environ = 'raw_datasets/kegg_medicus_environ_en.csv'\n",
    "kegg_medicus_network = 'raw_datasets/kegg_medicus_network.csv'\n",
    "kegg_medicus_variant = 'raw_datasets/kegg_medicus_variant.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_drug_df = pd.read_csv(kegg_medicus_drug)\n",
    "raw_disease_df = pd.read_csv(kegg_medicus_disease)\n",
    "raw_dgroup_df = pd.read_csv(kegg_medicus_dgroup)\n",
    "raw_environ_df = pd.read_csv(kegg_medicus_environ)\n",
    "raw_network_df = pd.read_csv(kegg_medicus_network)\n",
    "raw_variant_df = pd.read_csv(kegg_medicus_variant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty variable for preprocessing function\n",
    "row_to_dict = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_datasets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataframe_to_list(df):\n",
    "    result_list = df.apply(row_to_dict, axis=1).tolist()\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kegg Medicus Drug Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_drug_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_drug_df.groupby('classification')['classification'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_drug_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['component', 'sequence', 'source', 'db_links', 'sequence type', \n",
    "           'dblinks_w_link', 'comment_w_link', 'target_w_link', 'disease', 'disease_w_link',\n",
    "           'remark_w_link', 'image', 'raw_entry_id', 'class', 'original', 'repeat',\n",
    "           'efficacy_w_link','source_w_link','metabolism_w_link','sequence_w_link',\n",
    "            'interaction_w_link','component_w_link','class_w_link', 'interaction','kcf','atom', 'bond',\n",
    "            'bracket', 'remark','metabolism','target']\n",
    "clean_drug_df = raw_drug_df[[col for col in raw_drug_df.columns if col not in exclude]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_drug_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_drug_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "def row_to_dict(row):\n",
    "    entry_id = row['entry_id']\n",
    "    name = row['name']\n",
    "    efficacy = row['efficacy']\n",
    "    comment = row['comment']\n",
    "    formula = row['formula']\n",
    "    exact_mass = row['exact_mass']\n",
    "    mol_weight = row['mol_weight']\n",
    "    classification = row['classification']\n",
    "    text = f\"name: {name}; formula: {formula}; efficacy: {efficacy}; comment: {comment}\"\n",
    "    output_dict = {\n",
    "            \"id\": entry_id,\n",
    "            \"input\": text,\n",
    "            \"metadata\": {\n",
    "                \"name\": name,\n",
    "                \"text\": text,\n",
    "                \"classification\": classification,\n",
    "                \"formula\": formula,\n",
    "                \"exact mass\": exact_mass,\n",
    "                \"mol_weight\": mol_weight\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_preprocess = convert_dataframe_to_list(clean_drug_df)\n",
    "print(len(drugs_preprocess))\n",
    "drugs_preprocess[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_df = pd.DataFrame(drugs_preprocess)\n",
    "preprocessed_datasets.append(drugs_df)\n",
    "print(drugs_df.shape)\n",
    "drugs_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kegg Medicus Disease Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_disease_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_disease_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_disease_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['SUBGROUP', 'SUPERGRP', 'NETWORK', 'ENTRY_link',\n",
    "           'SUBGROUP_link', 'SUPERGRP_link', 'DESCRIPTION_link',\n",
    "           'NETWORK_link', 'GENE_link', 'PATHOGEN_link', 'ENV_FACTOR_link',\n",
    "           'CARCINOGEN_link', 'DRUG_link', 'COMMENT_link','DBLINKS_link',\n",
    "           'REFERENCE_link', 'DBLINKS', 'REFERENCE']\n",
    "clean_disease_df = raw_disease_df[[col for col in raw_disease_df.columns if col not in exclude]]\n",
    "clean_disease_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "def row_to_dict(row):\n",
    "    entry_id = row['ENTRY']\n",
    "    name = row['NAME']\n",
    "    description = row['DESCRIPTION']\n",
    "    comment = row['COMMENT']\n",
    "    category = row['CATEGORY']\n",
    "    gene = row['GENE']\n",
    "    pathogen = row['PATHOGEN']\n",
    "    env_factor = row['ENV_FACTOR']\n",
    "    carcinogen = row['CARCINOGEN']\n",
    "    drug = row['DRUG']\n",
    "    text = f\"name: {name}; category: {category}; description: {description}; drug: {drug}\"\n",
    "\n",
    "    output_dict = {\n",
    "            \"id\": entry_id,\n",
    "            \"input\": text,\n",
    "            \"metadata\": {\n",
    "                \"name\": name,\n",
    "                \"text\": text,\n",
    "                \"gene\": gene,\n",
    "                \"pathogen\": pathogen,\n",
    "                \"env_factor\": env_factor,\n",
    "                \"carcinogen\": carcinogen,\n",
    "                \"drug\": drug,\n",
    "                \"comment\": comment,\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_preprocess = convert_dataframe_to_list(clean_disease_df)\n",
    "print(len(disease_preprocess))\n",
    "disease_preprocess[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_df = pd.DataFrame(disease_preprocess)\n",
    "preprocessed_datasets.append(disease_df)\n",
    "print(disease_df.shape)\n",
    "disease_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kegg Medicus D-Group Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dgroup_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dgroup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['CLASSIFICATION','STEM','IMAGE','COMMENT','CLASS_link','ENTRY_link','REMARK_link','MEMBER_link']\n",
    "clean_dgroup_df = raw_dgroup_df[[col for col in raw_dgroup_df.columns if col not in exclude]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dgroup_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dgroup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "def row_to_dict(row):\n",
    "    entry_id = row['ENTRY']\n",
    "    name = row['NAME']\n",
    "    class_item = row['CLASS']\n",
    "    remark = row['REMARK']\n",
    "    member = row['MEMBER']\n",
    "    text = f\"name: {name}; member: {member}; class: {class_item};  remark: {remark}\"\n",
    "\n",
    "    output_dict = {\n",
    "            \"id\": entry_id,\n",
    "            \"input\": text,\n",
    "            \"metadata\": {\n",
    "                \"text\": text,\n",
    "                \"name\": name,\n",
    "                \"class\": class_item\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgroup_preprocess = convert_dataframe_to_list(clean_dgroup_df)\n",
    "print(len(dgroup_preprocess))\n",
    "dgroup_preprocess[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgroup_df = pd.DataFrame(dgroup_preprocess)\n",
    "preprocessed_datasets.append(dgroup_df)\n",
    "print(dgroup_df.shape)\n",
    "dgroup_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kegg Medicus Environ Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_environ_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_environ_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['Remark', 'Other DBs']\n",
    "clean_environ_df = raw_environ_df[[col for col in raw_environ_df.columns if col not in exclude]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_environ_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_environ_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4\n",
    "def row_to_dict(row):\n",
    "    entry_id = row['E number']\n",
    "    name = row['Name']\n",
    "    category = row['Category']\n",
    "    component = row['Component']\n",
    "    source = row['Source']\n",
    "    comment = row['Comment']\n",
    "    text = f\"name: {name}; category: {category}; component: {comment} comment: {comment}; source: {source}\"\n",
    "\n",
    "    output_dict = {\n",
    "            \"id\": entry_id,\n",
    "            \"input\": text,\n",
    "            \"metadata\": {\n",
    "                \"name\": name, \n",
    "                \"text\": text,\n",
    "                \"component\": component,\n",
    "                \n",
    "            }\n",
    "        }\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environ_preprocess = convert_dataframe_to_list(clean_environ_df)\n",
    "print(len(environ_preprocess))\n",
    "environ_preprocess[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environ_df = pd.DataFrame(environ_preprocess)\n",
    "preprocessed_datasets.append(environ_df)\n",
    "print(environ_df.shape)\n",
    "environ_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kegg Medicus Network Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_network_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_network_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['ENTRY_link','VARIANT','METABOLITE','PERTURBANT','DEFINITION_link', 'EXPANDED_link', 'CLASS_link', 'DISEASE_link', 'GENE_link', 'VARIANT_link',\n",
    "           'METABOLITE_link', 'PERTURBANT_link','REFERENCE_link']\n",
    "clean_network_df = raw_network_df[[col for col in raw_network_df.columns if col not in exclude]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_network_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_network_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_network_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5\n",
    "def row_to_dict(row):\n",
    "    entry_id = row['ENTRY']\n",
    "    name = row['NAME']\n",
    "    definition = row['DEFINITION']\n",
    "    expanded = row['EXPANDED']\n",
    "    item_class = row['CLASS']\n",
    "    item_type = row['TYPE']\n",
    "    disease = row['DISEASE']\n",
    "    gene = row['GENE']\n",
    "    text = f\"name: {name}; definition: {definition}; expanded: {expanded}; class: {item_class}, type: {item_type}\"\n",
    "\n",
    "    output_dict = {\n",
    "            \"id\": entry_id,\n",
    "            \"input\": text,\n",
    "            \"metadata\": {\n",
    "                \"name\": name,\n",
    "                \"text\": text,\n",
    "                \"name\": name,\n",
    "                \"class\": item_class,\n",
    "                \"comment\": item_type,\n",
    "                \"disease\": disease,\n",
    "                \"gene\":gene\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_preprocess = convert_dataframe_to_list(clean_network_df)\n",
    "print(len(network_preprocess))\n",
    "network_preprocess[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_df = pd.DataFrame(network_preprocess)\n",
    "preprocessed_datasets.append(network_df)\n",
    "print(network_df.shape)\n",
    "network_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kegg Medicus Variant Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_variant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_variant_df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_variant_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = ['ENTRY_link', 'NETWORK_link', 'GENE_link','ORGANISM', 'VARIATION_link',\n",
    "           'ELEMENT_link', 'REFERENCE_link']\n",
    "clean_variant_df = raw_variant_df[[col for col in raw_variant_df.columns if col not in exclude]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_variant_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_variant_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "def row_to_dict(row):\n",
    "    entry_id = row['ENTRY']\n",
    "    name = row['NAME']\n",
    "    gene = row['GENE']\n",
    "    variation = row['VARIATION']\n",
    "    network = row['NETWORK']\n",
    "    element = row['ELEMENT']\n",
    "    reference = row['REFERENCE']\n",
    "    text = f\"name: {name}; gene: {gene}; variation: {variation}; network{network}; element{element}\"\n",
    "\n",
    "    output_dict = {\n",
    "            \"id\": entry_id,\n",
    "            \"input\": text,\n",
    "            \"metadata\": {\n",
    "                \"name\": name,\n",
    "                \"text\": text,\n",
    "                \"network\": network,\n",
    "                \"element\": element,\n",
    "                \"reference\": reference\n",
    "            }\n",
    "        }\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_preprocess = convert_dataframe_to_list(clean_variant_df)\n",
    "print(len(variant_preprocess))\n",
    "variant_preprocess[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_df = pd.DataFrame(variant_preprocess)\n",
    "preprocessed_datasets.append(variant_df)\n",
    "print(variant_df.shape)\n",
    "variant_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing (Creating Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "    return embed.embed_documents(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in preprocessed_datasets:\n",
    "    print(f\"indexing {df.shape}\")\n",
    "    df['values'] = df['input'].apply(get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs_index = drugs_df.drop(['input'], axis=1)\n",
    "drugs_dataset = pd.DataFrame.to_csv(drugs_index)\n",
    "#with open('index_datasets/drugs.csv', 'w') as f: \n",
    "#    f.write(drugs_dataset)\n",
    "index_data.append(drugs_index)\n",
    "drugs_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_index = disease_df.drop(['input'], axis=1)\n",
    "disease_dataset = pd.DataFrame.to_csv(disease_index)\n",
    "#with open('index_datasets/disease.csv', 'w') as f: \n",
    "#    f.write(disease_dataset)\n",
    "index_data.append(disease_index)\n",
    "disease_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgroup_index = dgroup_df.drop(['input'], axis=1)\n",
    "dgroup_dataset = pd.DataFrame.to_csv(dgroup_index)\n",
    "#with open('index_datasets/dgroup.csv', 'w') as f: \n",
    "#   f.write(dgroup_dataset)\n",
    "index_data.append(dgroup_index)\n",
    "dgroup_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environ_index = environ_df.drop(['input'], axis=1)\n",
    "environ_dataset = pd.DataFrame.to_csv(environ_index)\n",
    "#with open('index_datasets/environ.csv', 'w') as f: \n",
    "#    f.write(environ_dataset)\n",
    "index_data.append(environ_index)\n",
    "environ_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_index = variant_df.drop(['input'], axis=1)\n",
    "variant_dataset = pd.DataFrame.to_csv(variant_index)\n",
    "#with open('index_datasets/variant.csv', 'w') as f: \n",
    "#    f.write(variant_dataset)\n",
    "index_data.append(variant_index)\n",
    "variant_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_index =  network_df.drop(['input'], axis=1)\n",
    "network_dataset = pd.DataFrame.to_csv(network_index)\n",
    "index_data.append\n",
    "#with open('index_datasets/network.csv', 'w') as f: \n",
    "#    f.write(network_dataset)\n",
    "index_data.append(network_index)\n",
    "network_index.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"kegg-medicus-database-index\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\katle\\anaconda3\\envs\\dl_env\\Lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\katle\\Documents\\GitHub\\chatbot_prototype\\notebooks\\kegg_medicus_database_indexer.ipynb Cell 86\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/katle/Documents/GitHub/chatbot_prototype/notebooks/kegg_medicus_database_indexer.ipynb#Y151sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpinecone\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/katle/Documents/GitHub/chatbot_prototype/notebooks/kegg_medicus_database_indexer.ipynb#Y151sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m pinecone_api_key \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetenv(\u001b[39m'\u001b[39m\u001b[39mPINECONE_API_KEY\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/katle/Documents/GitHub/chatbot_prototype/notebooks/kegg_medicus_database_indexer.ipynb#Y151sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m pinecone\u001b[39m.\u001b[39minit(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/katle/Documents/GitHub/chatbot_prototype/notebooks/kegg_medicus_database_indexer.ipynb#Y151sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     api_key\u001b[39m=\u001b[39mos\u001b[39m.\u001b[39menviron[\u001b[39m'\u001b[39m\u001b[39mPINECONE_API_KEY\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/katle/Documents/GitHub/chatbot_prototype/notebooks/kegg_medicus_database_indexer.ipynb#Y151sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     environment\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgcp-starter\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/katle/Documents/GitHub/chatbot_prototype/notebooks/kegg_medicus_database_indexer.ipynb#Y151sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/katle/Documents/GitHub/chatbot_prototype/notebooks/kegg_medicus_database_indexer.ipynb#Y151sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mif\u001b[39;00m index_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pinecone\u001b[39m.\u001b[39mlist_indexes():\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/katle/Documents/GitHub/chatbot_prototype/notebooks/kegg_medicus_database_indexer.ipynb#Y151sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m# we create a new index\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=os.environ['PINECONE_API_KEY'],\n",
    "    environment='gcp-starter'\n",
    ")\n",
    "\n",
    "if index_name not in pinecone.list_indexes():\n",
    "    # we create a new index\n",
    "    pinecone.create_index(\n",
    "        name=index_name,\n",
    "        metric='dotproduct',\n",
    "        dimension= len(result[0])  # 1536 dim of text-embedding-ada-002\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_medicus_index = pinecone.GRPCIndex(index_name)\n",
    "kegg_medicus_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in index_data:\n",
    "    kegg_medicus_index.upsert_from_dataframe(df, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_medicus_index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle '_thread.RLock' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\katle\\Documents\\GitHub\\chatbot_prototype\\notebooks\\kegg_medicus_database_indexer.ipynb Cell 91\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/katle/Documents/GitHub/chatbot_prototype/notebooks/kegg_medicus_database_indexer.ipynb#Y155sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m \u001b[39m# Cache the vector database using cloudpickle\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/katle/Documents/GitHub/chatbot_prototype/notebooks/kegg_medicus_database_indexer.ipynb#Y155sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(index_filename, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/katle/Documents/GitHub/chatbot_prototype/notebooks/kegg_medicus_database_indexer.ipynb#Y155sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m     cloudpickle\u001b[39m.\u001b[39;49mdump(vector_data, f)\n",
      "File \u001b[1;32mc:\\Users\\katle\\anaconda3\\envs\\dl_env\\Lib\\site-packages\\cloudpickle\\cloudpickle.py:1461\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol, buffer_callback)\u001b[0m\n\u001b[0;32m   1448\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, buffer_callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1449\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Serialize obj as bytes streamed into file\u001b[39;00m\n\u001b[0;32m   1450\u001b[0m \n\u001b[0;32m   1451\u001b[0m \u001b[39m    protocol defaults to cloudpickle.DEFAULT_PROTOCOL which is an alias to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1459\u001b[0m \u001b[39m    next).\u001b[39;00m\n\u001b[0;32m   1460\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1461\u001b[0m     Pickler(file, protocol\u001b[39m=\u001b[39;49mprotocol, buffer_callback\u001b[39m=\u001b[39;49mbuffer_callback)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "File \u001b[1;32mc:\\Users\\katle\\anaconda3\\envs\\dl_env\\Lib\\site-packages\\cloudpickle\\cloudpickle.py:1245\u001b[0m, in \u001b[0;36mPickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m   1243\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(\u001b[39mself\u001b[39m, obj):\n\u001b[0;32m   1244\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1245\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdump(obj)\n\u001b[0;32m   1246\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1247\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(e\u001b[39m.\u001b[39margs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mrecursion\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m e\u001b[39m.\u001b[39margs[\u001b[39m0\u001b[39m]:\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle '_thread.RLock' object"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import dill\n",
    "import os\n",
    "import pinecone\n",
    "import cloudpickle \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "pinecone_api_key = os.getenv('PINECONE_API_KEY')\n",
    "\n",
    "pinecone.init(\n",
    "    api_key=os.environ['PINECONE_API_KEY'],\n",
    "    environment='gcp-starter'\n",
    ")\n",
    "\n",
    "index_name = \"kegg-medicus-database-index\"\n",
    "index_filename = \"cached_index.joblib\"\n",
    "\n",
    "index_filename = \"cached_vector_database.pkl\"\n",
    "\n",
    "if os.path.exists(index_filename):\n",
    "    # Load cached vector database if it exists\n",
    "    with open(index_filename, 'rb') as f:\n",
    "        vector_data = cloudpickle.load(f)\n",
    "else:\n",
    "    # Create vector database (your original vector data fetching logic)\n",
    "    vector_data = index = pinecone.Index(index_name)\n",
    "\n",
    "    # Cache the vector database using cloudpickle\n",
    "    with open(index_filename, 'wb') as f:\n",
    "        cloudpickle.dump(vector_data, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
